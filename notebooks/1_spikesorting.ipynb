{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NWB-Datajoint tutorial 1\n",
    "\n",
    "**Note: make a copy of this notebook and run the copy to avoid git conflicts in the future**\n",
    "\n",
    "This is the first in a multi-part tutorial on the NWB-Datajoint pipeline used in Loren Frank's lab, UCSF. It demonstrates how to run spike sorting within the pipeline.\n",
    "\n",
    "If you have not done [tutorial 0](0_intro.ipynb) yet, make sure to do so before proceeding.\n",
    "\n",
    "Let's start by importing the `nwb_datajoint` package, along with a few others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import nwb_datajoint as nd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)  # ignore datajoint+jupyter async warning\n",
    "\n",
    "# Comment these if you have already set these environment variables\n",
    "data_dir = Path('/stelmo/nwb') # CHANGE ME TO THE BASE DIRECTORY FOR DATA STORAGE ON YOUR SYSTEM\n",
    "os.environ['DJ_SUPPORT_FILEPATH_MANAGEMENT'] = 'TRUE'\n",
    "os.environ['NWB_DATAJOINT_BASE_DIR'] = str(data_dir)\n",
    "os.environ['KACHERY_STORAGE_DIR'] = str(data_dir / 'kachery-storage')\n",
    "os.environ['SPIKE_SORTING_STORAGE_DIR'] = str(data_dir / 'spikesorting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also import a bunch of tables so that we can call them easily\n",
    "from nwb_datajoint.common import (RawPosition, HeadDir, Speed, LinPos, StateScriptFile, VideoFile,\n",
    "                                  DataAcquisitionDevice, CameraDevice, Probe,\n",
    "                                  DIOEvents,\n",
    "                                  ElectrodeGroup, Electrode, Raw, SampleCount,\n",
    "                                  LFPSelection, LFP, LFPBandSelection, LFPBand,\n",
    "                                  SortGroup, SpikeSorting, SpikeSorter, SpikeSorterParameters, SpikeSortingWaveformParameters, SpikeSortingParameters, SpikeSortingMetrics, CuratedSpikeSorting,\n",
    "                                  FirFilter,\n",
    "                                  IntervalList, SortInterval,\n",
    "                                  Lab, LabMember, Institution,\n",
    "                                  BrainRegion,\n",
    "                                  SensorData,\n",
    "                                  Session, ExperimenterList,\n",
    "                                  Subject,\n",
    "                                  Task, TaskEpoch,\n",
    "                                  Nwbfile, AnalysisNwbfile, NwbfileKachery, AnalysisNwbfileKachery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will continue to work with the copy of `beans20190718.nwb` that you created in tutorial 0. If you deleted it from `Session`, make sure to re-insert before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the file that you copied and renamed; make sure it's something unique. \n",
    "nwb_file_name = 'beans20190718.nwb'\n",
    "filename, file_extension = os.path.splitext(nwb_file_name)\n",
    "# This is a copy of the original nwb file, except it doesn't contain the raw data (for storage reasons)\n",
    "nwb_file_name2 = filename + '_' + file_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run if you need to reinsert the data\n",
    "nd.insert_sessions(nwb_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike sorting\n",
    "\n",
    "In general, running spike sorting means making decisions about the following:\n",
    "1. which eletrodes to sort together (e.g. electrodes that form a tetrode should be sorted together, but tetrodes that are far apart need not be);\n",
    "2. which time interval to sort (e.g. there may a long period in the recording where nothing happens, and we might want to exclude that);\n",
    "3. which spike sorter to use (e.g. Mountainsort? Kilosort? IronClust?);\n",
    "4. given choice of the spike sorter in 3, which parameter set to use.\n",
    "\n",
    "In our Datajoint framework, everything that we do is an interaction with a table. This is true for spike sorting as well - i.e. we think of spike sorting as a process where we enter parameters of spike sorting (i.e. our decisions about the four questions above) into tables, and use that information to populate another table that will hold the result of spike sorting. Under the hood, we use a number of packages, notably `spikeinterface`. But the user need not know this - they just have to interact with the table. This makes spike sorting straightforward. In addition, the entries in these tables serve as a record of exactly which decisions you made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sort group\n",
    "We start with the first question: which electrodes do we want to sort together? We first inspect the `Electrode` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Electrode & {'nwb_file_name': nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This recording was done with polymer probes. Here `electrode_group_name` refers to a probe. We can see that there were two probes, `0` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique probe id\n",
    "np.unique((Electrode & {'nwb_file_name': nwb_file_name2}).fetch('electrode_group_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each probe has four shanks, as you can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique shank id for the first probe\n",
    "np.unique((Electrode & {'nwb_file_name': nwb_file_name2, 'electrode_group_name': 0}).fetch('probe_shank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our job is to identify the electrodes that we want to sort together, and add them as a sort group in the `SortGroup` table. One natural way to do this is to set each shank as a sort group (for tetrode recordings, each tetrode can be thought of as a \"shank\" with four electrodes). Use `set_group_by_shank` method for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortGroup().set_group_by_shank(nwb_file_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates 8 sort groups, one for each of the four shanks in the two probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortGroup & {'nwb_file_name': nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SortGroup` has a *parts table* called `SortGroupElectrode` - think of this as child table that contains information auxiliary to the parent table. As you can see, it contains two extra attributes: `electrode_group_name` and `electrode_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortGroup.SortGroupElectrode & {'nwb_file_name': nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you don't want to sort by shank? Maybe you want to select specific electrodes across shanks and sort them. To do so, you just have to manually `insert` a new entry into the `SortGroup` and `SortGroupElectrode` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_group_id = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we make a new entry in the SortGroup table, and give it sort_group_id of 8\n",
    "SortGroup.insert1({'nwb_file_name': nwb_file_name2, 'sort_group_id': sort_group_id, 'sort_reference_electrode_id': -1}, \n",
    "                  skip_duplicates = True)\n",
    "# Next, we will associate with the sort group that we just created every fourth electrode of the first shank\n",
    "SortGroup.SortGroupElectrode.insert([[nwb_file_name2, 8, 0, elec] for elec in range(0,32,4)], skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `insert` is a method, just like `fetch`. You can insert an entry in the form of a dictionary or a list in the order of the attributes. We can look at the new entries we just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortGroup & {'nwb_file_name' : nwb_file_name2, 'sort_group_id' : sort_group_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortGroup.SortGroupElectrode & {'nwb_file_name': nwb_file_name2, 'sort_group_id': sort_group_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sort interval\n",
    "Next, we make a decision about the time interval for our spike sorting. Let's re-examine `IntervalList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntervalList & {'nwb_file_name' : nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, let's just decide the first 10 seconds of the first run interval (`02_r1`) as our sort interval. To do so, we first fetch `valid_times` of this interval, define our new sort interval, and add this to the `SortInterval` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_list_name = '02_r1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (IntervalList & {'nwb_file_name' : nwb_file_name2,\n",
    "                            'interval_list_name' : interval_list_name}).fetch1('valid_times')\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_interval = np.asarray([interval[0][0]+10, interval[0][0]+20])\n",
    "print(sort_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out SortInterval\n",
    "SortInterval & {'nwb_file_name' : nwb_file_name2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_interval_name = 'beans_02_r1_10s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the required attributes\n",
    "SortInterval.insert1({'nwb_file_name' : nwb_file_name2,\n",
    "                      'sort_interval_name' : sort_interval_name,\n",
    "                      'sort_interval' : sort_interval}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See results\n",
    "SortInterval & {'nwb_file_name' : nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sorter\n",
    "Next we decide which spike sorter to use. This boils down to looking at the `SpikeSorter` table and choosing the one we like. Initially, `SpikeSorter` may not be populated; in that case, we insert some sorters to it by checking which ones are available via `spikeinterface`, the package that we will be using implicitly for spike sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorter().insert_from_spikeinterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, we will be using `mountainsort4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_name='mountainsort4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sorter parameters\n",
    "Once we have decided on a spike sorter, we have to set parameters. Some of these parameters are common to all sorters (e.g. frequency band to filter the raw data before sorting begins) but most are specific to the sorter that we chose. Again, we populate `SpikeSorterParameters` table with some default parameters for each sorter, and then we add our version as a new entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorterParameters().insert_from_spikeinterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorterParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new set of spike sorter parameters from default and add to table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the default params\n",
    "ms4_default_params = (SpikeSorterParameters & {'sorter_name' : sorter_name,\n",
    "                                               'parameter_set_name' : 'default'}).fetch1()\n",
    "print(ms4_default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default params\n",
    "param_dict = ms4_default_params['parameter_dict']\n",
    "# We will just sort electrodes one by one\n",
    "param_dict['adjacency_radius'] = 0\n",
    "param_dict['curation'] = False\n",
    "# Turn filter off since we will filter it prior to starting sort\n",
    "param_dict['filter'] = False\n",
    "# set num_workers to be the same number as the number of electrodes\n",
    "param_dict['num_workers'] = len((SortGroup.SortGroupElectrode & {'sort_group_id':sort_group_id}).fetch('electrode_id'))\n",
    "param_dict['verbose'] = True\n",
    "# set clip size as number of samples for 2 milliseconds\n",
    "param_dict['clip_size'] = np.int(2e-3 * (Raw & {'nwb_file_name' : nwb_file_name2}).fetch1('sampling_rate'))\n",
    "param_dict['noise_overlap_threshold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a unique name here\n",
    "parameter_set_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert\n",
    "SpikeSorterParameters.insert1({'sorter_name' : sorter_name,\n",
    "                               'parameter_set_name' : parameter_set_name,\n",
    "                               'parameter_dict' : param_dict}, skip_duplicates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that insert was successful\n",
    "SpikeSorterParameters & {'sorter_name' : sorter_name, 'parameter_set_name' : parameter_set_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define qualtiy metric parameters\n",
    "\n",
    "We're almost done. There are more parameters related to how to compute the quality metrics for curation. We just use the default options here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use `test`\n",
    "SpikeSortingMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_metrics_list_name = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing everything together\n",
    "\n",
    "We now collect all the decisions we made up to here and put it into `SpikeSortingParameters` table (note: this is different from spike sor*ter* parameters defined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the params\n",
    "key = dict()\n",
    "key['nwb_file_name'] = nwb_file_name2\n",
    "key['sort_group_id'] = sort_group_id\n",
    "key['sort_interval_name'] = sort_interval_name\n",
    "key['interval_list_name'] = interval_list_name\n",
    "key['sorter_name'] = sorter_name\n",
    "key['parameter_set_name'] = parameter_set_name\n",
    "key['cluster_metrics_list_name'] = cluster_metrics_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert\n",
    "SpikeSortingParameters.insert1(key, skip_duplicates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect\n",
    "SpikeSortingParameters & {'nwb_file_name' : nwb_file_name2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running spike sorting\n",
    "Now we can run spike sorting. As we said it's nothing more than populating another table (`SpikeSorting`) from the entries of `SpikeSortingParameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify entry (otherwise runs everything in SpikeSortingParameters); `proj` gives you primary key\n",
    "SpikeSorting.populate([(SpikeSortingParameters & {'nwb_file_name' : nwb_file_name2}).proj()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorting & {'nwb_file_name' : nwb_file_name2}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
